{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5563fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "\n",
    "import igraph\n",
    "import networkx as nx\n",
    "import metis\n",
    "import ALLCools\n",
    "from ALLCools.integration.seurat_class import SeuratIntegration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938fac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_subclasses(adata, n_partitions):\n",
    "    '''Assign integration partitions as the adata.obs['integration_partion'] column.'''\n",
    "    adata.obs['integration_partition'] = 'p0'\n",
    "    \n",
    "    # Get a sparse matrix of that counts edges between subclasses\n",
    "    ones = adata.obsp['distances'].copy()\n",
    "    ones.data = np.ones(len(ones.data))\n",
    "\n",
    "    g_neighobrs = sc._utils.get_igraph_from_adjacency(ones, directed=True)\n",
    "    vc = igraph.VertexClustering(g_neighobrs, membership=adata.obs['subclass_label'].cat.codes.values)\n",
    "    cluster_mtx = sc._utils.get_sparse_from_igraph(vc.cluster_graph(combine_edges='sum'), weight_attr='weight')\n",
    "    \n",
    "    # Partition the cluster level graph\n",
    "    G_cluster = nx.from_scipy_sparse_array(cluster_mtx)\n",
    "    for i in adata.obs['subclass_label'].cat.codes.values:\n",
    "        G_cluster.nodes[i]['weight'] = np.sum(adata.obs['subclass_label'] \n",
    "                                              == adata.obs['subclass_label'].cat.categories[i] )\n",
    "    G_cluster.graph['node_weight_attr'] = 'weight'\n",
    "    \n",
    "    (cut, parts) = metis.part_graph(G_cluster, n_partitions, recursive=False,\n",
    "                                   tpwgts=[1 / n_partitions] * n_partitions) \n",
    "    \n",
    "    # Assign the partitions\n",
    "    for i in range(len(parts)):\n",
    "        mask = (adata.obs['subclass_label'] == adata.obs['subclass_label'].cat.categories[i])\n",
    "        adata.obs.loc[mask, 'integration_partition'] = 'p' + str(parts[i])\n",
    "    \n",
    "    adata.obs['integration_partition'] = adata.obs['integration_partition'].astype('category')\n",
    "    \n",
    "import scipy.sparse\n",
    "def get_cluster_mean_expression_matrix(adata, cluster_column):\n",
    "    '''Get a dataframe of mean gene expression of each cluster.'''\n",
    "    if scipy.sparse.issparse(adata.X):\n",
    "        X = adata.X.toarray()\n",
    "    else:\n",
    "        X = adata.X\n",
    "   \n",
    "    cell_exp_mtx = pd.DataFrame(X, index=adata.obs[cluster_column], columns=adata.var.index)    \n",
    "    return cell_exp_mtx.groupby(by=cluster_column).mean()\n",
    "\n",
    "def calculate_correlation_matrix(adata, cluster_column):\n",
    "    '''Calculate gene expression correlations between clusters.'''\n",
    "    cluster_mean_exp = get_cluster_mean_expression_matrix(adata, cluster_column)\n",
    "    \n",
    "    # Initialzie the correlation matrix\n",
    "    cluster_ids = np.array(cluster_mean_exp.index)\n",
    "    N_clusters = len(cluster_ids)\n",
    "    correlation_mtx = pd.DataFrame(np.ones((N_clusters, N_clusters)), index=cluster_ids, columns=cluster_ids)\n",
    "    \n",
    "    # Fill the correlation matrix\n",
    "    for i in range(N_clusters):\n",
    "        cluster_id1 = cluster_ids[i]\n",
    "        mean_exps1 = np.array(cluster_mean_exp.loc[cluster_id1])\n",
    "        \n",
    "        for j in range(i + 1, N_clusters):\n",
    "            cluster_id2 = cluster_ids[j]\n",
    "            mean_exps2 = np.array(cluster_mean_exp.loc[cluster_id2])\n",
    "            \n",
    "            r, p = scipy.stats.pearsonr(mean_exps1, mean_exps2)\n",
    "\n",
    "            correlation_mtx.loc[cluster_id1, cluster_id2] = r\n",
    "            correlation_mtx.loc[cluster_id2, cluster_id1] = r\n",
    "            \n",
    "    return correlation_mtx\n",
    "\n",
    "def merge_clusters(obs_df, cluster_col, clusters_to_merge):\n",
    "    merged_cluster_id = sorted(clusters_to_merge)[0]\n",
    "    obs_df[cluster_col][obs_df[cluster_col].isin(clusters_to_merge)] = merged_cluster_id\n",
    "    obs_df[cluster_col] = obs_df[cluster_col].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c564980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "workspace_path = 'integration_workspace'\n",
    "input_seq_file = 'standardize_scRNAseq/AIT21_combined.h5ad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37075dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the top level directories\n",
    "os.makedirs(workspace_path, exist_ok=True)\n",
    "partition_path = os.path.join(workspace_path, 'partitions')\n",
    "os.makedirs(partition_path, exist_ok=True)\n",
    "os.makedirs(os.path.join(workspace_path, 'gene_expression_imputation'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf7f20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load the sequencing data\n",
    "adata_seq = sc.read_h5ad(input_seq_file)\n",
    "\n",
    "adata_seq.obs['subclass_label'] = adata_seq.obs['subclass_label'].astype('category')\n",
    "adata_seq.obs['cl'] = adata_seq.obs['cl'].astype('category')\n",
    "\n",
    "# Load the merfish data\n",
    "adata_merfish = sc.read_h5ad('/home/xingjiepan/data/whole_brain/MERFISH/20230602_cellpose2/merfish_raw_cp2.h5ad')\n",
    "\n",
    "# Rename the genes with different synonyms names\n",
    "adata_merfish.var.rename(index={\n",
    "    'AC102910.1': 'Gm30564', \n",
    "    'BC030499': 'Rskr',\n",
    "    'Ctgf': 'Ccn2',\n",
    "    'Fam196b': 'Insyn2b',\n",
    "    'Fam19a1': 'Tafa1',\n",
    "    'Fam19a2': 'Tafa2',\n",
    "    'Fam19a4': 'Tafa4',\n",
    "    'Fam46a': 'Tent5a',\n",
    "    'Fam84b': 'Lratd2',\n",
    "    'Nov': 'Ccn3',\n",
    "    'Wisp1': 'Ccn4',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fdd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the common genes\n",
    "common_genes = np.array(adata_seq.var_names.intersection(adata_merfish.var_names))\n",
    "adata_merfish = adata_merfish[:, adata_merfish.var.index.isin(common_genes)]\n",
    "adata_merfish.write_h5ad(os.path.join(workspace_path, 'adata_merfish.h5ad'), compression='gzip')\n",
    "\n",
    "adata_seq._inplace_subset_var(common_genes)\n",
    "\n",
    "# Remove the cells without cluster or subclass labels\n",
    "adata_seq = adata_seq[~adata_seq.obs['cl'].isna()]\n",
    "adata_seq = adata_seq[~adata_seq.obs['subclass_label'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391cfa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the integration partitions using the sequencing data\n",
    "n_partitions = 80\n",
    "\n",
    "sc.pp.normalize_total(adata_seq, target_sum=1000)\n",
    "sc.pp.log1p(adata_seq)\n",
    "sc.pp.scale(adata_seq)\n",
    "\n",
    "n_pcs=100\n",
    "sc.tl.pca(adata_seq, svd_solver='arpack', n_comps=n_pcs)\n",
    "sc.pp.neighbors(adata_seq, use_rep='X_pca', n_neighbors=15, n_pcs=n_pcs)\n",
    "\n",
    "partition_subclasses(adata_seq, n_partitions)\n",
    "\n",
    "#Merge partitions with too few cells\n",
    "partition_corr_df = calculate_correlation_matrix(adata_seq, 'integration_partition')\n",
    "p_names, p_n_cells = np.unique(adata_seq.obs['integration_partition'], return_counts=True)\n",
    "p_smalls = p_names[p_n_cells < 10000]\n",
    "p_larges = p_names[p_n_cells >= 10000]\n",
    "partition_corr_df = partition_corr_df.loc[p_smalls, p_larges]\n",
    "\n",
    "for p1 in p_smalls:\n",
    "\n",
    "    p2 = partition_corr_df.columns[np.argmax(partition_corr_df.loc[p1])]\n",
    "    \n",
    "    print(f'Merge partitions {p1} and {p2}')\n",
    "    merge_clusters(adata_seq.obs, 'integration_partition', [p1, p2])\n",
    "    \n",
    "seq_annotation_df = adata_seq.obs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78809db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Reload the sequencing data and assign the partitions\n",
    "adata_seq = sc.read_h5ad(input_seq_file)\n",
    "adata_seq.obs['integration_partition'] = seq_annotation_df['integration_partition']\n",
    "\n",
    "adata_seq.obs['subclass_label'] = adata_seq.obs['subclass_label'].astype('category')\n",
    "adata_seq.obs['cl'] = adata_seq.obs['cl'].astype('category')\n",
    "\n",
    "adata_seq = adata_seq[~adata_seq.obs['cl'].isna()]\n",
    "adata_seq = adata_seq[~adata_seq.obs['subclass_label'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Split the sequencing data for the input of the final round of integration.\n",
    "# Because imputation is done at this round, all genes are included.\n",
    "partitions = adata_seq.obs['integration_partition'].cat.categories\n",
    "\n",
    "print('Partition, N_cells, subclasses')\n",
    "for pn in partitions:\n",
    "    adata_subset = adata_seq[adata_seq.obs['integration_partition'] == pn]\n",
    "    p = os.path.join(partition_path, pn.replace('/', '-').replace(' ', '_'))\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "    adata_subset.write_h5ad(os.path.join(p, 'adata_seq.h5ad'), compression='gzip')\n",
    "    \n",
    "    print(f'{pn}, {adata_subset.shape[0]}, {list(np.unique(adata_subset.obs[\"subclass_label\"]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826458a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subseting anndata requires creating an intermediate copy which\n",
    "# explode the memory. The solution is to reload the partitioned\n",
    "# anndata from the disk.\n",
    "del adata_seq, adata_merfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f99e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the adata files with common genes\n",
    "\n",
    "adata_seq_cg_list = []\n",
    "for pn in os.listdir(partition_path):\n",
    "    print(pn)\n",
    "    adata_seq = sc.read_h5ad(os.path.join(partition_path, pn, 'adata_seq.h5ad'))\n",
    "    adata_seq = adata_seq[:, adata_seq.var.index.isin(common_genes)].copy()\n",
    "    adata_seq_cg_list.append(adata_seq)\n",
    "    \n",
    "adata_seq_cg = anndata.concat(adata_seq_cg_list)\n",
    "adata_seq_cg.write_h5ad(os.path.join(workspace_path, 'adata_seq_common_genes.h5ad'), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449d32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
