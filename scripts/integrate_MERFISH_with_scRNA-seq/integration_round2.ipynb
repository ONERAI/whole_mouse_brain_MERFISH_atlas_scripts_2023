{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8761bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "sc.settings.n_jobs = 56\n",
    "sc.settings.set_figure_params(dpi=180, dpi_save=300, frameon=False, figsize=(4, 4), fontsize=8, facecolor='white')\n",
    "\n",
    "import ALLCools\n",
    "from ALLCools.integration.seurat_class import SeuratIntegration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "workspace_path = 'integration_workspace'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c33a99",
   "metadata": {},
   "source": [
    "# Integrate individual partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11afd707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_gene_expression(integrator, adata_list, X_ref, ref=0, qry=1, npc=30, kweight=30, sd=1,\n",
    "                           chunk_size=1000, random_state=0):\n",
    "    data_qry = adata_list[qry].obsm['X_pca']\n",
    "\n",
    "    anchor, G, D, cum_qry = integrator.find_nearest_anchor(adata_list, data_qry=data_qry, ref=[ref], qry=[qry],\n",
    "                                                      npc=npc, kweight=kweight, sd=sd, random_state=random_state)\n",
    "    \n",
    "    if scipy.sparse.issparse(X_ref):\n",
    "        X_ref = X_ref.toarray()\n",
    "    \n",
    "    X_anchor = X_ref[anchor[:, 0]]\n",
    "    imputed_chunks = []\n",
    "    \n",
    "    for chunk_start in np.arange(0, data_qry.shape[0], chunk_size):\n",
    "        imputed_chunks.append(scipy.sparse.csr_matrix((\n",
    "                        D[chunk_start:(chunk_start + chunk_size), :, None] *\n",
    "                        X_anchor[G[chunk_start:(chunk_start + chunk_size)]]\n",
    "                    ).sum(axis=1).astype(np.float32)))\n",
    "\n",
    "    return scipy.sparse.vstack(imputed_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imputation_path = os.path.join(workspace_path, 'gene_expression_imputation')\n",
    "partition_path = os.path.join(workspace_path, 'partitions')\n",
    "partitions = sorted(os.listdir(partition_path))\n",
    "\n",
    "for pn in partitions:\n",
    "    print(f'Integrate for {pn}')\n",
    "    integration_path = os.path.join(partition_path, pn)\n",
    "    input_adata_seq_file = os.path.join(integration_path, 'adata_seq.h5ad')\n",
    "    input_adata_merfish_file = os.path.join(integration_path, 'adata_merfish_integrated.h5ad')\n",
    "    \n",
    "    if not (os.path.exists(input_adata_seq_file) and os.path.exists(input_adata_merfish_file)):\n",
    "        print('Missing input file. Skip the integration.')\n",
    "        continue\n",
    "        \n",
    "    ## Load and preprocess the data\n",
    "    adata_seq_raw = sc.read_h5ad(input_adata_seq_file)\n",
    "    adata_seq = adata_seq_raw.copy()\n",
    "    adata_merfish_raw = sc.read_h5ad(input_adata_merfish_file)\n",
    "    adata_merfish = adata_merfish_raw.copy()\n",
    "\n",
    "    # Consider the common genes\n",
    "    common_genes = np.array(adata_seq.var_names.intersection(adata_merfish.var_names))\n",
    "    adata_seq._inplace_subset_var(common_genes)\n",
    "    \n",
    "    # Normalize\n",
    "    sc.pp.normalize_total(adata_seq, target_sum=1000)\n",
    "    sc.pp.log1p(adata_seq)\n",
    "    sc.pp.normalize_total(adata_merfish, target_sum=1000)\n",
    "    sc.pp.log1p(adata_merfish)\n",
    "    \n",
    "    # Normalize the raw data for imputation\n",
    "    # The reason to normalize the raw count is to avoid cells with\n",
    "    # high total counts to dominate and bias the imputed expressions.\n",
    "    sc.pp.normalize_total(adata_seq_raw, target_sum=1e4)\n",
    "    \n",
    "    # Select variable genes\n",
    "    sc.pp.highly_variable_genes(adata_seq)\n",
    "    hv_genes = list(adata_seq.var.index[adata_seq.var['dispersions'] > 0])\n",
    "    adata_seq = adata_seq[:, adata_seq.var.index.isin(hv_genes)]\n",
    "    adata_merfish = adata_merfish[:, adata_merfish.var.index.isin(hv_genes)]\n",
    "    print(f'Use {len(hv_genes)} highly variable genes for integration.')\n",
    "    \n",
    "    # Scale the data\n",
    "    sc.pp.scale(adata_seq)\n",
    "    sc.pp.scale(adata_merfish)\n",
    "    \n",
    "    # Merge the datasets\n",
    "    adata_merge = adata_seq.concatenate(adata_merfish,\n",
    "                                    batch_categories=['seq', 'merfish'],\n",
    "                                    batch_key='modality',\n",
    "                                    index_unique=None)\n",
    "    \n",
    "    # PCA\n",
    "    n_pcs = min(100, len(hv_genes) - 1)\n",
    "    sc.tl.pca(adata_merge, svd_solver='arpack', n_comps=n_pcs)\n",
    "    \n",
    "    adata_list = [adata_merge[adata_merge.obs['modality'] == 'seq'],\n",
    "                  adata_merge[adata_merge.obs['modality'] == 'merfish']]\n",
    "    \n",
    "    ## Integration\n",
    "    # Find the integration anchors\n",
    "    integrator = SeuratIntegration()\n",
    "    integrator.find_anchor(adata_list,\n",
    "                       k_local=None,\n",
    "                       key_local='X_pca',\n",
    "                       k_anchor=5,\n",
    "                       key_anchor='X',\n",
    "                       dim_red='cca',\n",
    "                       max_cc_cells=100000,\n",
    "                       k_score=30,\n",
    "                       k_filter=None, #why?\n",
    "                       scale1=False,\n",
    "                       scale2=False,\n",
    "                       n_components=n_pcs,\n",
    "                       n_features=200,\n",
    "                       alignments=[[[0], [1]]])\n",
    "    \n",
    "    # Label transfer\n",
    "    #cell_type_cols = ['Level1_label', 'Level2_label', 'cl']\n",
    "    cell_type_cols = ['subclass_label', 'cl']\n",
    "    transfer_results = integrator.label_transfer(\n",
    "        ref=[0],\n",
    "        qry=[1],\n",
    "        categorical_key=cell_type_cols,\n",
    "        key_dist='X_pca',\n",
    "        kweight=30,\n",
    "        npc=n_pcs\n",
    "    )\n",
    "    integrator.save_transfer_results_to_adata(adata_merge, transfer_results)\n",
    "    \n",
    "    # Assign the transfered labels and the confidence\n",
    "    for cell_type_col in cell_type_cols:\n",
    "        adata_merfish_raw.obs[cell_type_col + '_transfer'] = transfer_results[cell_type_col].idxmax(axis=1\n",
    "                                                                                           ).astype('category')\n",
    "        adata_merfish_raw.obs[cell_type_col + '_confidence'] = transfer_results[cell_type_col].max(axis=1)\n",
    "        \n",
    "        n_transfered = len(np.unique(adata_merfish_raw.obs[cell_type_col + '_transfer']))\n",
    "        n_total = len(np.unique(adata_merge.obs[cell_type_col + '_transfer']))\n",
    "        print(f'Transfered {n_transfered}/{n_total} {cell_type_col}.')\n",
    "    \n",
    "    # Save the label transfer results\n",
    "    adata_merfish_raw.write_h5ad(os.path.join(integration_path, 'adata_merfish_label_transfer.h5ad'), \n",
    "                                 compression='gzip')     \n",
    "    \n",
    "    # Impute gene expression\n",
    "    X_imputed = impute_gene_expression(integrator, adata_list, adata_seq_raw.X, \n",
    "                                       ref=0, qry=1, npc=n_pcs, chunk_size=5000)\n",
    "    adata_imputed = anndata.AnnData(X=X_imputed, obs=adata_merfish_raw.obs.copy(), \n",
    "                                var=adata_seq_raw.var.copy(), dtype=np.float32)\n",
    "    \n",
    "    # Create the imputation gene partition table\n",
    "    gene_partition_file = os.path.join(imputation_path, 'gene_partition.csv')\n",
    "    if not os.path.exists(gene_partition_file):\n",
    "        gene_partition_df = adata_seq_raw.var.copy()\n",
    "        gene_partition_df.index.name = 'gene'\n",
    "        gene_partition_df['gene_partition'] = np.arange(gene_partition_df.shape[0], dtype=int) // 1000\n",
    "        gene_partition_df.to_csv(gene_partition_file)\n",
    "        \n",
    "    else:\n",
    "        gene_partition_df = pd.read_csv(gene_partition_file).set_index('gene')\n",
    "    \n",
    "    gene_partitions = np.unique(gene_partition_df['gene_partition'])\n",
    "    \n",
    "    # Save the imputation results\n",
    "    for sn in np.unique(adata_imputed.obs['subclass_label_transfer']):\n",
    "        adata_subset = adata_imputed[adata_imputed.obs['subclass_label_transfer'] == sn]\n",
    "        \n",
    "        os.makedirs(os.path.join(imputation_path, sn.replace('/', '-').replace(' ', '_')), exist_ok=True)\n",
    "        for g_p in gene_partitions:\n",
    "            p_genes = np.array(gene_partition_df[gene_partition_df['gene_partition'] == g_p].index)\n",
    "            adata_ct_p = adata_subset[:, adata_subset.var.index.isin(p_genes)]\n",
    "            adata_ct_p.write_h5ad(os.path.join(imputation_path, sn.replace('/', '-').replace(' ', '_'), \n",
    "                                               f'{g_p}.h5ad'), compression='gzip')\n",
    "\n",
    "        \n",
    "    ## Co-embedding\n",
    "    # Correct the PCs using the integration anchors\n",
    "    corrected = integrator.integrate(key_correct='X_pca',\n",
    "                                 row_normalize=True,\n",
    "                                 n_components=n_pcs,\n",
    "                                 k_weight=100,\n",
    "                                 sd=1,\n",
    "                                 alignments=[[[0], [1]]])\n",
    "\n",
    "    adata_merge.obsm['X_pca_integrate'] = np.concatenate(corrected)\n",
    "    \n",
    "    # Calculate KNN using the integrated PCs\n",
    "    sc.pp.neighbors(adata_merge, use_rep='X_pca_integrate')\n",
    "    \n",
    "    if len(np.unique(adata_merge.obs['subclass_label_transfer'])) > 1:\n",
    "        # Generate the PAGA plot for the initial arrangement of the UMAP\n",
    "        sc.tl.paga(adata_merge, groups='subclass_label_transfer')\n",
    "        sc.pl.paga(adata_merge, save='_tmp.png', cmap='gist_ncar')\n",
    "        shutil.move('figures/paga_tmp.png', os.path.join(integration_path, 'integration_paga_round2.png'))\n",
    "    \n",
    "        sc.tl.umap(adata_merge, init_pos='paga', min_dist=0.5)\n",
    "    else:\n",
    "        sc.tl.umap(adata_merge, min_dist=0.5)\n",
    "        \n",
    "    # Save the umap\n",
    "    sc.pl.umap(adata_merge, color='modality', save='_tmp.png')\n",
    "    shutil.move('figures/umap_tmp.png', os.path.join(integration_path, 'integration_umap_modality.png'))\n",
    "    #sc.pl.umap(adata_merge, color='Level1_label_transfer', save='_tmp.png')\n",
    "    #shutil.move('figures/umap_tmp.png', os.path.join(integration_path, 'integration_umap_Level1_label.png'))\n",
    "    sc.pl.umap(adata_merge, color='subclass_label_transfer', save='_tmp.png', palette='gist_ncar')\n",
    "    shutil.move('figures/umap_tmp.png', os.path.join(integration_path, 'integration_umap_subclass_label.png'))\n",
    "    sc.pl.umap(adata_merge, color='cl_transfer', save='_tmp.png', palette='gist_ncar')\n",
    "    shutil.move('figures/umap_tmp.png', os.path.join(integration_path, 'integration_umap_cl.png'))\n",
    "    \n",
    "    \n",
    "    # Save the merged adata\n",
    "    adata_merge.write_h5ad(os.path.join(integration_path, 'adata_merged_round2.h5ad'), compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066e9e0",
   "metadata": {},
   "source": [
    "# Combine the integration results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a1b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import scipy.spatial\n",
    "\n",
    "def get_cluster_mean_expression_matrix(adata, cluster_column):\n",
    "    '''Get a dataframe of mean gene expression of each cluster.'''\n",
    "    if scipy.sparse.issparse(adata.X):\n",
    "        X = adata.X.toarray()\n",
    "    else:\n",
    "        X = adata.X\n",
    "   \n",
    "    cell_exp_mtx = pd.DataFrame(X, index=adata.obs[cluster_column], columns=adata.var.index)    \n",
    "    return cell_exp_mtx.groupby(by=cluster_column).mean()\n",
    "\n",
    "\n",
    "def calc_cell_cosines_to_cluster_mean_exps(adata, cluster_col, cluster_mean_exp_df):\n",
    "    cluster_mean_exp_df = cluster_mean_exp_df.loc[:, adata.var.index]\n",
    "    cluster_id_map = {cluster_mean_exp_df.index[i]:i for i in range(cluster_mean_exp_df.shape[0])}\n",
    "    cell_cluster_ids = np.array(adata.obs[cluster_col].map(cluster_id_map))\n",
    "    \n",
    "    X_cluster_mean = cluster_mean_exp_df.values[cell_cluster_ids]\n",
    "    \n",
    "    if scipy.sparse.issparse(adata.X):\n",
    "        X = adata.X.toarray()\n",
    "    else:\n",
    "        X = adata.X\n",
    "    \n",
    "    cosines = []\n",
    "    for i in range(adata.shape[0]):\n",
    "        if np.sum(X[i]) > 0:\n",
    "            cosines.append(1 - scipy.spatial.distance.cosine(X[i], X_cluster_mean[i]))\n",
    "        else:\n",
    "            cosines.append(0)\n",
    "    \n",
    "    return cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45521952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the label transfer results\n",
    "adatas = []\n",
    "for pn in partitions:\n",
    "    adata_file = os.path.join(partition_path, pn, 'adata_merfish_label_transfer.h5ad')\n",
    "    adatas.append(sc.read_h5ad(adata_file))\n",
    "    \n",
    "adata = anndata.concat(adatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3633c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean expressions of each cluster\n",
    "adata_seq = sc.read_h5ad(os.path.join(workspace_path, 'adata_seq_common_genes.h5ad'))\n",
    "sc.pp.normalize_total(adata_seq, target_sum=1000)\n",
    "sc.pp.log1p(adata_seq)\n",
    "\n",
    "cluster_mean_exp_df = get_cluster_mean_expression_matrix(adata_seq, 'cl')\n",
    "\n",
    "# Get the MERFISH log1p expressions\n",
    "adata_merfish_log1p = adata.copy()\n",
    "sc.pp.normalize_total(adata_merfish_log1p, target_sum=1000)\n",
    "sc.pp.log1p(adata_merfish_log1p)\n",
    "\n",
    "# Calcualte the cluster cosine similarities\n",
    "adata.obs['cluster_cosine_similarity'] = calc_cell_cosines_to_cluster_mean_exps(adata_merfish_log1p, \n",
    "                                                    'cl_transfer', cluster_mean_exp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b63f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.obs['adjusted_Level1_label_confidence'] = (adata.obs['integration_partition_confidence'] \n",
    "#                                                        * adata.obs['Level1_label_confidence'])\n",
    "adata.obs['adjusted_subclass_label_confidence'] = (adata.obs['integration_partition_confidence'] \n",
    "                                                        * adata.obs['subclass_label_confidence'])\n",
    "adata.obs['adjusted_cl_confidence'] = adata.obs['integration_partition_confidence'] * adata.obs['cl_confidence']\n",
    "\n",
    "\n",
    "adata.write_h5ad(os.path.join(workspace_path, 'adata_merfish_label_transfer.h5ad'), compression='gzip')\n",
    "adata.obs.to_csv(os.path.join(workspace_path, 'adata_merfish_label_transfer_metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('N_Level1_label =', len(np.unique(adata.obs['Level1_label_transfer'])))\n",
    "print('N_subclass_label =', len(np.unique(adata.obs['subclass_label_transfer'])))\n",
    "print('N_clusters =', len(np.unique(adata.obs['cl_transfer'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f998b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.obs['integration_partition_confidence'], bins=30)\n",
    "plt.title('partition_confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb34a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(adata.obs['Level1_label_confidence'], bins=30)\n",
    "#plt.title('Level1_label_confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082634f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.obs['subclass_label_confidence'], bins=30)\n",
    "plt.title('subclass_label_confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e666759",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.obs['adjusted_subclass_label_confidence'], bins=30)\n",
    "plt.title('Adjusted level2 confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3675593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.obs['cl_confidence'], bins=30)\n",
    "plt.title('cl_confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a319a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.obs['adjusted_cl_confidence'], bins=30)\n",
    "plt.title('Adjusted cluster confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.obs['cluster_cosine_similarity'], bins=30)\n",
    "plt.title('Cluster cosine similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c86e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda90063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
